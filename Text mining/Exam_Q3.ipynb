{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Q3 Nadine Kanbier - 4283724\n",
    "#### A television producer has approached you with the question whether they should release the new season of their show all at once, like Netflix does, or once a week. As their market research has shown that both release strategies will result in more or less the same ratings, they want to know which release strategy will engage their audiences more; which release strategy will result in more (valuable) discussions. Try to formulate a good operationalization of this question using the methods we discussed in the last three weeks, and argue why this operationalization would be suitable to formulate a substantiated advice for the television producer. Then implement your operationalization using discussions.p (where the column â€˜typeâ€™ indicates whether a show is released all in once [value â€™netflixâ€™] or linearly [value â€™linearâ€™]). Try to formulate a substantiated advice for the television producer. If your method doesnâ€™t produce meaningful results, try to formulate suggestions on how to improve the method you proposed instead. Note: you will not be graded on the extent to which your proposed method actually produces valuable results, but on your thought process and argumentation. Donâ€™t try to fine-tune your method until it spits out something interesting.\n",
    "\n",
    "##### Your answer must consist of the following:\n",
    "##### â€¢ An operationalization of the question (ca. 350 words)\n",
    "##### â€¢ The complete code to answer the question with a short comment for every step (max. 2 sentences per step)\n",
    "##### â€¢ Interpretation and conclusion (ca. 200 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operationalization:\n",
    "\n",
    "Television and social media are deeply intertwined: social network sites such as Twitter or Reddit allow viewers to enjoy the communal experience of group viewing without being physically together. Therefore, it is important to find out how viewers are using the social network sites when watching a TV show. For producers, it is important to know if there is a difference between releasing techniques.\n",
    "\n",
    "Engagement is often measured by its volume and rates. We want to know which release technique (at once or per episode) produce **valuable** discussions. So first, we have to define valuable discussions. \n",
    "\n",
    "A post like: *I love this show. But it's hard to argue against its pace. It's sooooooooooo slooooowww. The writing, the acting, the direction, the production, all of it top notch. That however, doesn't mean we can't complain it's \"boring\". It's a different kind of boring, but I totally get the critique and I feel the same way. The story takes way too long to develop. It's great to have slower paced TV, but I think this show over does it.* seems like more of a valuable discussion than a post like: *'lol'*.\n",
    "\n",
    "Therefore, we will compare the amount of words in each post per release strategy. We define valuable as more tokens per post. Because we only want the valuable words, we tokenize the posts and remove stop words.\n",
    "\n",
    "After this, we will compare the results per release strategy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                                     Better Call Saul\n",
       "type                                                linear\n",
       "year                                                  2016\n",
       "post     I love this show. But it's hard to argue again...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('discussions_corrected.csv')\n",
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3526.9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of posts per 'linear' tv show\n",
    "(df.post[df.type == 'linear'].count())/(df.title[df.type == 'linear'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1473.1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of posts per 'netflix' tv show\n",
    "(df.post[df.type == 'netflix'].count())/(df.title[df.type == 'netflix'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: \n",
    "The average number of posts does not equal engagement per se: the average of the posts is influenced by the popularity of shows such as Game of Thrones. This does not produce a sensible answer on its own. So we will now tokenize the words in the posts and remove stop words. This way, we can see which technique produces more (and more valuable!) discussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the text\n",
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def spacy_tokenizer(str_list):\n",
    "    processed_texts = [text for text in nlp.pipe(str_list,\n",
    "                                             n_threads=-1)]\n",
    "\n",
    "    tokenized_texts = [[word.lemma_ for word in text \n",
    "                        if not word.is_punct and not word.is_stop] \n",
    "                       for text in processed_texts]\n",
    "    \n",
    "    return tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding it to the dataframe\n",
    "tokenized_posts=spacy_tokenizer(df['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>post</th>\n",
       "      <th>tokens</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2017</td>\n",
       "      <td>Walter. And there the chain ends.</td>\n",
       "      <td>[Walter, chain, end]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>I love this show. But it's hard to argue again...</td>\n",
       "      <td>[love, hard, argue, pace, sooooooooooo, sloooo...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2017</td>\n",
       "      <td>What am I missing?  A lot of reference to ribs...</td>\n",
       "      <td>[miss,  , lot, reference, ribs, burger, Carls,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2018</td>\n",
       "      <td>Oh come on Mike, he's a good little boy.</td>\n",
       "      <td>[oh, come, Mike, good, little, boy]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2017</td>\n",
       "      <td>Look again ðŸ‘€</td>\n",
       "      <td>[look, ðŸ‘€]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title    type  year  \\\n",
       "0  Better Call Saul  linear  2017   \n",
       "1  Better Call Saul  linear  2016   \n",
       "2  Better Call Saul  linear  2017   \n",
       "3  Better Call Saul  linear  2018   \n",
       "4  Better Call Saul  linear  2017   \n",
       "\n",
       "                                                post  \\\n",
       "0                  Walter. And there the chain ends.   \n",
       "1  I love this show. But it's hard to argue again...   \n",
       "2  What am I missing?  A lot of reference to ribs...   \n",
       "3          Oh come on Mike, he's a good little boy.    \n",
       "4                                       Look again ðŸ‘€   \n",
       "\n",
       "                                              tokens  length  \n",
       "0                               [Walter, chain, end]       3  \n",
       "1  [love, hard, argue, pace, sooooooooooo, sloooo...      57  \n",
       "2  [miss,  , lot, reference, ribs, burger, Carls,...       9  \n",
       "3                [oh, come, Mike, good, little, boy]       6  \n",
       "4                                          [look, ðŸ‘€]       2  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens']=tokenized_posts # tokenized posts in dataframe\n",
    "df['length'] = df['tokens'].apply(len) # length of tokenized post in dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting\n",
    "linear = df[df.type == 'linear']\n",
    "netflix = df[df.type == 'netflix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.04661317304148"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.length.mean() # average tokens per post when type is linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.537098635530514"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix.length.mean() # average tokens per post when type is netflix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "\n",
    "Results show that the linear shows in our dataset produce more posts (and therefore, more engagement). There is a limitation to this statement however: the popularity of the TV shows in our dataset varied. Game of Thrones greatly increased the amount of posts. This is why we looked at the number of words(tokens) in each posts.\n",
    "\n",
    "Our results show that netflix shows produce more valuable (longer) discussions. The average number of words (not counting stop words) is higher for the netflix strategy than for the linear strategy. \n",
    "\n",
    "Therefore, as an answer to the question which release strategy will result in more valuable discussions, I would recommend using the Netflix strategy. The recent show 'Queen's Gambit' popularity is a great example to further support this claim. https://www.businessinsider.com/data-shows-netflix-queens-gambit-a-word-of-mouth-hit-2020-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
