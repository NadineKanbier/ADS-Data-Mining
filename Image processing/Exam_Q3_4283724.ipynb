{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - 4283724 Nadine Kanbier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the subsets of movie trailers from 1920-1940, 1960-1980 and 2000-2020 from exercise 6.1, but instead of comparing the shot types and shot lengths, use one of the (pre-trained) image feature extraction methods we discussed in exercise 5.2 to compare the subsets, and explain your choice.\n",
    "##### [Note: you are not allowed to use the same method you used in Q2. So if you analyzed gender in Q2, you have to pick something else for this question.]\n",
    "##### Make a plan for tackling the dimensionality of the data: each subset consists of multiple videos, each video consist of multiple frames/seconds/shots, and each frame/second/shot could contain multiple faces/genders/emotions/objects/-texts/colors. How are you going to compare the subsets? Explain the choices you make carefully. Then implement your plan and interpret the results.\n",
    "\n",
    "##### Your answer must consist of the following:\n",
    "##### • Explanation of choice for features, plan for tackling the dimensionality (ca. 350 words)\n",
    "##### • The complete code to answer the question with a short comment for every step (max. 2 sentences per step)\n",
    "##### • Interpretation and conclusion (ca. 200 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan\n",
    "It is commonly thought that ‘older’ movies are in black and white and more recent movies are in color. However, there is no distinct dividing line between the two [1]. On top of that, filmmakers continue to choose to shoot their films in black and white (e.g. Schindler’s List (1993) and The Artist (2011)) [2]. \n",
    "\n",
    "Because there is no distinct dividing line, it is interesting to look at it from a time-series analysis approach. Before this can be done on on a larger scale using multiple subsets (e.g. subsets per decade or even per year), we will take a look at more general subsets: 1920-1940, 1960-1980 and 2000-2020. I will be comparing the number of dominant colors between these subsets. Findings could provide an overview of dominant color-use in the different periods.\n",
    "\n",
    "To analyze this, we need a plan to tackle the dimensionality of the data. The process will be as follows:\n",
    "Step 1. Making the subsets out of the trailers data. \n",
    "Step 2. Getting the middle frame of the scenes for each video. Looking at all the frames would be computationally intensive and we would end up with a lot of the same frames. Because we are analyzing the most dominant colors, looking at scenes only will be sufficient. More specifically, we will look at the middle frame of the scene. \n",
    "Step 3. Loading the frames for each subset. \n",
    "Step 4. Using the package colorgram, we will look at the number of dominant colors in each subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing the subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "from scenedetect import VideoManager\n",
    "from scenedetect import SceneManager\n",
    "\n",
    "from scenedetect.detectors import ContentDetector\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import wget\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import wget\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import colorgram\n",
    "from matplotlib.colors import to_hex\n",
    "\n",
    "import webcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I make and download the subsets\n",
    "trailers = pd.read_csv('trailers.csv')\n",
    "\n",
    "trailers_20 = trailers[(trailers.year > 1920) & (trailers.year < 1940)].sample(3)\n",
    "trailers_60 = trailers[(trailers.year > 1960) & (trailers.year < 1980)].sample(3)\n",
    "trailers_00= trailers[trailers.year > 2000].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_sample(df, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.mkdir(folder)\n",
    "    \n",
    "    video_paths = []\n",
    "    for video in df.itertuples():\n",
    "        video_url = video.url\n",
    "        output_path = folder + video.trailer_title + '.mp4'\n",
    "        filename = wget.download(video_url, out=output_path)\n",
    "        video_paths.append(output_path)\n",
    "        \n",
    "    return video_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trailer1920 = dl_sample(trailers_20, 'vid_1920/')\n",
    "trailer1960 = dl_sample(trailers_60, 'vid_1960/')\n",
    "trailer2000 = dl_sample(trailers_00, 'vid_2000/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Downloading the middle frame of each scene for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define find scenes.\n",
    "def find_scenes(video_path, threshold=10.0):\n",
    "    video_manager = VideoManager([video_path])\n",
    "    scene_manager = SceneManager()\n",
    "    scene_manager.add_detector(\n",
    "        ContentDetector(threshold=threshold))\n",
    "    base_timecode = video_manager.get_base_timecode()\n",
    "    video_manager.set_downscale_factor()\n",
    "    video_manager.start()\n",
    "    scene_manager.detect_scenes(frame_source=video_manager, show_progress=False)    \n",
    "    return scene_manager.get_scene_list(base_timecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download scenes.\n",
    "def dl_scenes(filename):\n",
    "    # create list of scenes\n",
    "    scene_list = find_scenes(filename, threshold=10)\n",
    "    \n",
    "    # get the middle frame of the scenes\n",
    "    frames = []\n",
    "    \n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    \n",
    "    for start_time, end_time in scene_list:\n",
    "        duration = end_time - start_time\n",
    "        frame = (start_time.get_frames() + int(duration.get_frames() / 2))\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES,frame)\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "    \n",
    "    # save the scenes\n",
    "    if not os.path.exists('scenes/'):\n",
    "        os.mkdir('scenes/')\n",
    "\n",
    "    for i, frame in enumerate(frames):\n",
    "        cv2.imwrite('scenes/frame_{}.jpg'.format(i), frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trailers(videos):\n",
    "    for vid in videos:\n",
    "        dfs.append(dl_scenes(vid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots1920 = analyze_trailers(trailer1920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots1960 = analyze_trailers(trailer1960)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots2000 = analyze_trailers(trailer2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loading the frames for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define load image from path.\n",
    "\n",
    "%config InlineBackend.figure_format='retina' \n",
    "\n",
    "def load_image_from_path(image_path, target_size=None, color_mode='rgb'):\n",
    "    pil_image = image.load_img(image_path, \n",
    "                               target_size=target_size,\n",
    "                            color_mode=color_mode)\n",
    "    return image.img_to_array(pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, define the path and create the dataframe.\n",
    "\n",
    "mypath1 = '/Users/nadinekanbier/Desktop/Applied Data Science/Periode 2/Data Mining/Exam 2/vid_1920/scenes'\n",
    "\n",
    "image_paths1 = [image_path.path for image_path in os.scandir(mypath1)] # the image paths\n",
    "image_paths1 = [image for image in image_paths1 if image[-3:] in ['jpg', 'gif', 'epg', 'png']]\n",
    "\n",
    "df1920 = pd.DataFrame(image_paths1) \n",
    "df1920.columns = ['file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath2 = '/Users/nadinekanbier/Desktop/Applied Data Science/Periode 2/Data Mining/Exam 2/vid_1960/scenes'\n",
    "\n",
    "image_paths2 = [image_path.path for image_path in os.scandir(mypath2)] # the image paths\n",
    "image_paths2 = [image for image in image_paths2 if image[-3:] in ['jpg', 'gif', 'epg', 'png']]\n",
    "\n",
    "df1960 = pd.DataFrame(image_paths2) \n",
    "df1960.columns = ['file_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath3 = '/Users/nadinekanbier/Desktop/Applied Data Science/Periode 2/Data Mining/Exam 2/vid_2000/scenes'\n",
    "\n",
    "image_paths3 = [image_path.path for image_path in os.scandir(mypath3)] # the image paths\n",
    "image_paths3 = [image for image in image_paths3 if image[-3:] in ['jpg', 'gif', 'epg', 'png']]\n",
    "\n",
    "df2000 = pd.DataFrame(image_paths3)\n",
    "df2000.columns = ['file_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Getting the most dominant colors for each subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get colours\n",
    "def get_colour_name(rgb_triplet):\n",
    "    \"\"\"\n",
    "    From https://stackoverflow.com/questions/9694165/convert-rgb-color-to-english-color-name-like-green-with-python\n",
    "    \"\"\"\n",
    "    min_colours = {}\n",
    "    for key, name in webcolors.CSS21_HEX_TO_NAMES.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - rgb_triplet[0]) ** 2\n",
    "        gd = (g_c - rgb_triplet[1]) ** 2\n",
    "        bd = (b_c - rgb_triplet[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91fd3a74e2c41268a8d1521d4ba3cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=73.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "colors_list = []\n",
    "\n",
    "for i in tqdm(range(0,len(df1920))):\n",
    "    color_image = load_image_from_path(df1920.file_path.values[i],color_mode='rgb')\n",
    "    img = Image.fromarray(color_image.astype(np.uint8)) # convert to PIL image object\n",
    "    colors = colorgram.extract(img, 1) \n",
    "\n",
    "    for color in colors:\n",
    "        rgb = tuple(color.rgb)\n",
    "        color_name = get_colour_name(rgb)\n",
    "    \n",
    "    colors_list.append(color_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['black', 'gray'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1920['Dominant_color'] = colors_list\n",
    "df1920['Dominant_color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1920-40 subset has two most dominant colors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79815d1fd5604ff1b2fb947d44fcc377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=264.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "colors_list = []\n",
    "\n",
    "for i in tqdm(range(0,len(df1960))):\n",
    "    color_image = load_image_from_path(df1960.file_path.values[i],color_mode='rgb')\n",
    "    img = Image.fromarray(color_image.astype(np.uint8)) # convert to PIL image object\n",
    "    colors = colorgram.extract(img, 1) \n",
    "\n",
    "    for color in colors:\n",
    "        rgb = tuple(color.rgb)\n",
    "        color_name = get_colour_name(rgb)\n",
    "    \n",
    "    colors_list.append(color_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['black', 'gray', 'silver'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1960['Dominant_color'] = colors_list\n",
    "df1960['Dominant_color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1960-1980 subset has three most dominant colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd767d0086648318f32ca75e30060b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=203.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "colors_list = []\n",
    "\n",
    "for i in tqdm(range(0,len(df2000))):\n",
    "    color_image = load_image_from_path(df2000.file_path.values[i],color_mode='rgb')\n",
    "    img = Image.fromarray(color_image.astype(np.uint8)) # convert to PIL image object\n",
    "    colors = colorgram.extract(img, 1) \n",
    "\n",
    "    for color in colors:\n",
    "        rgb = tuple(color.rgb)\n",
    "        color_name = get_colour_name(rgb)\n",
    "    \n",
    "    colors_list.append(color_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['black', 'gray', 'white', 'navy', 'orange', 'silver', 'olive',\n",
       "       'aqua', 'teal'], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2000['Dominant_color'] = colors_list\n",
    "df2000['Dominant_color'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 2000-2020 subset has nine most dominant colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and discussion\n",
    "\n",
    "The analysis shows us that the early period (1920-1940) uses only two dominant colors. This is expected, although color films were introduced in the 1920, black and white movies were dominating the cinematic world. The second period (1960-1980) uses only three dominant colors in its trailers. The last period (2000-2020) uses nine dominant colors, a significant difference compared to the other periods. This suggest that sometime during the last periods, the number of dominant colors in movies rised. This analysis provides cause to further research the color-use in movies throughout the decades. \n",
    "\n",
    "That being said, we have to be careful when interpreting the results. We have only used three trailers for each subset/period. Further research with more trailers and more subsets is necessary to provide a time-series analysis on the color-use in movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. https://www.liveabout.com/how-movies-went-from-black-white-to-color-4153390\n",
    "2. Li, J. (2012). Discoloured vestiges of history: Black and white in the age of colour cinema. Journal of Chinese Cinemas, 6(3), 247-262."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
